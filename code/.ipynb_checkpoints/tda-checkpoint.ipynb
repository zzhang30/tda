{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzhang30/.conda/envs/tda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import tree_sitter_java as tsjava\n",
    "from tree_sitter import Language, Parser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JAVA_LANGUAGE  = Language(tsjava.language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = Parser(JAVA_LANGUAGE)\n",
    "\n",
    "# Read and parse the Java file\n",
    "with open('ant-ivy/src/java/org/apache/ivy/Ivy.java', 'r') as f:\n",
    "    java_code = f.read()\n",
    "\n",
    "# Parse the code to get the syntax tree\n",
    "tree = parser.parse(bytes(java_code, \"utf8\"))\n",
    "root_node = tree.root_node\n",
    "\n",
    "# Traverse and print the parsed tree structure\n",
    "# def print_tree(node, indent=0):\n",
    "#     print('  ' * indent + node.type, node.start_point, node.end_point)\n",
    "#     for child in node.children:\n",
    "#         print_tree(child, indent + 1)\n",
    "\n",
    "# print_tree(root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#helper function for parsing each level\n",
    "def extract_code_fragments(node, code, level: str):\n",
    "    fragments = []\n",
    "    if level == \"class\" and node.type == \"class_declaration\":\n",
    "        fragments.append(code[node.start_byte:node.end_byte].decode('utf8'))\n",
    "    elif level == \"method\" and node.type == \"method_declaration\":\n",
    "        fragments.append(code[node.start_byte:node.end_byte].decode('utf8'))\n",
    "    elif level == \"token\" and len(node.children) == 0 and (node.type != 'block_comment' and node.type != 'line_comment'):\n",
    "        fragments.append(code[node.start_byte:node.end_byte].decode('utf8'))\n",
    "    \n",
    "    for child in node.children:\n",
    "        fragments.extend(extract_code_fragments(child, code, level))\n",
    "    \n",
    "    return fragments\n",
    "\n",
    "#parse one java file and \n",
    "def parse_java_file(file_path, level):\n",
    "    # Read Java file\n",
    "    with open(file_path, 'rb') as f:\n",
    "        java_code = f.read()\n",
    "\n",
    "    # Parse the file\n",
    "    JAVA_LANGUAGE  = Language(tsjava.language())\n",
    "    parser = Parser(JAVA_LANGUAGE)\n",
    "    tree = parser.parse(java_code)\n",
    "    root_node = tree.root_node\n",
    "\n",
    "    # Extract code fragments based on level\n",
    "    fragments = extract_code_fragments(root_node, java_code, level)\n",
    "    return fragments\n",
    "\n",
    "#\n",
    "def extract_from_project(directory, levels=[ \"class\", \"method\", \"token\"]):\n",
    "    project_fragments = {level: [] for level in levels}\n",
    "    \n",
    "    # Traverse directory to find all .java files\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".java\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Parsing {file_path}\")\n",
    "                \n",
    "                for level in levels:\n",
    "                    fragments = parse_java_file(file_path, level)\n",
    "                    project_fragments[level].extend(fragments)\n",
    "                    \n",
    "    return project_fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(extract_code_fragments(root_node, bytes(java_code, \"utf8\"), level = \"token\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "levels = [\"package\", \"class\", \"method\", \"token\"]\n",
    "# \n",
    "src_fragments = {level: [] for level in levels}\n",
    "\n",
    "for level in levels:\n",
    "        fragments = extract_code_fragments(root_node, bytes(java_code, \"utf8\"), level)\n",
    "        src_fragments[level].extend(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output each level of granularity\n",
    "for level, fragments in src_fragments.items():\n",
    "    print(f\"\\n--- {level.capitalize()} Level ---\")\n",
    "    for fragment in fragments:\n",
    "        print(fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tda)",
   "language": "python",
   "name": "tda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
